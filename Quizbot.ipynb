{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatische Erstellung von Quizfragen aus Lerntexten\n",
    "Dieses Notebook verwendet Natural Language Processing (NLP), um automatisch Quizfragen aus einem beliebigen Textdokument zu erstellen. Die Schritte umfassen das Einlesen des Lerntextes, das Verwenden eines vortrainierten Fragegenerierungsmodells und die Ausgabe der generierten Fragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Installation und Import von benötigten Bibliotheken\n",
    "Hier installieren und importieren wir die notwendigen Bibliotheken, darunter `transformers` für das vortrainierte Fragegenerierungsmodell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 2: Einlesen des Lerntextes\n",
    "Hier können Sie eine `.txt`-Datei hochladen, die den Lerntext enthält. Alternativ können Sie den Text direkt eingeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Hochladen und Lesen einer .txt-Datei\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "text = ''\n",
    "for filename in uploaded.keys():\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        print(f\"Inhalt von {filename} geladen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 3: Textsegmentierung\n",
    "Um spezifische Fragen zu einzelnen Abschnitten zu erstellen, wird der Text in kleinere Abschnitte aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in Sätze segmentieren\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "print(f\"Text in {len(sentences)} Sätze segmentiert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 4: Fragegenerierung\n",
    "Mit einem vortrainierten Modell werden automatisch Fragen zu den Textabschnitten erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fragegenerierungsmodell laden\n",
    "generator = pipeline('question-generation', model='valhalla/t5-small-qg-prepend')\n",
    "\n",
    "# Fragen für jeden Satz generieren\n",
    "questions = []\n",
    "for sentence in sentences:\n",
    "    try:\n",
    "        question = generator(sentence)\n",
    "        questions.append((sentence, question[0]['question']))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Fragegenerierung für den Satz: {sentence}\")\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 5: Ausgabe der generierten Fragen\n",
    "Hier werden die Fragen zusammen mit dem dazugehörigen Textabschnitt angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Fragen und ihrer jeweiligen Textabschnitte\n",
    "for i, (context, question) in enumerate(questions):\n",
    "    print(f\"Abschnitt {i+1}: {context}\")\n",
    "    print(f\"Frage {i+1}: {question}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
